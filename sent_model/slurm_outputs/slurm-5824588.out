Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
Training reference file: data/tamil/analysis/ref_of_queries_in_docs_train.txt
Validation reference file: data/tamil/analysis/ref_of_queries_in_docs_valid.txt
START TIME: 2024-07-22_21:28:10
Training model for tamil with inputs from mHuBERT layer 9
Number of epochs: 100, patience: 10, learning rate: 0.0005
clip norm: 10, temperature: 0.15, num pairs per batch: 2
time limit to create dataset: 600
weight decay: 0.05
temperature: 0.15

Created paired data
Created paired data
Time taken to create datasets: 58.87 s
Number of parameters in model: 6039552
Epoch 0: 0.05% done
Loss: 508.70442390441895
Time: 1.23 s
Epoch 0: 10.01% done
Loss: 486.20690837983165
Time: 2.24 s
Epoch 0: 20.03% done
Loss: 431.557412978706
Time: 2.73 s
Epoch 0: 30.04% done
Loss: 422.33900914498423
Time: 3.22 s
Epoch 0: 40.01% done
Loss: 386.826392953297
Time: 3.71 s
Epoch 0: 50.02% done
Loss: 374.0831280622734
Time: 4.21 s
Epoch 0: 60.04% done
Loss: 381.37041851536395
Time: 4.74 s
Epoch 0: 70.00% done
Loss: 339.9726639179865
Time: 5.22 s
Epoch 0: 80.02% done
Loss: 329.20323289383987
Time: 5.70 s
Epoch 0: 90.03% done
Loss: 364.027478491221
Time: 6.18 s

Epoch 0 done
Epoch loss: 384.95244564788845

Time taken for epoch: 6.66 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.01 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.02 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.03 s

Validation loss: 231.82011395692825

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_0.pt

Regenerated paired data
Epoch 1: 0.05% done
Loss: 104.85472679138184
Time: 0.00 s
Epoch 1: 10.01% done
Loss: 307.5834648949759
Time: 0.48 s
Epoch 1: 20.03% done
Loss: 313.66822887041155
Time: 0.97 s
Epoch 1: 30.04% done
Loss: 299.277182357437
Time: 1.46 s
Epoch 1: 40.01% done
Loss: 295.66161300180147
Time: 2.01 s
Epoch 1: 50.02% done
Loss: 332.2542742714969
Time: 2.43 s
Epoch 1: 60.04% done
Loss: 310.3521136789147
Time: 2.94 s
Epoch 1: 70.00% done
Loss: 292.5516356246263
Time: 3.42 s
Epoch 1: 80.02% done
Loss: 287.17783107465016
Time: 3.91 s
Epoch 1: 90.03% done
Loss: 284.3926932970318
Time: 4.40 s

Epoch 1 done
Epoch loss: 299.1391924608175

Time taken for epoch: 4.91 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.00 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 245.19991684291097

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_1.pt

Regenerated paired data
Epoch 2: 0.05% done
Loss: 10.394912213087082
Time: 0.00 s
Epoch 2: 10.01% done
Loss: 271.19017305187367
Time: 0.48 s
Epoch 2: 20.03% done
Loss: 265.5606339822327
Time: 0.95 s
Epoch 2: 30.04% done
Loss: 266.7489437454748
Time: 1.42 s
Epoch 2: 40.01% done
Loss: 278.95683910062513
Time: 1.90 s
Epoch 2: 50.02% done
Loss: 261.68915013688695
Time: 2.39 s
Epoch 2: 60.04% done
Loss: 248.2276497596721
Time: 2.91 s
Epoch 2: 70.00% done
Loss: 232.04735413125033
Time: 3.37 s
Epoch 2: 80.02% done
Loss: 256.2031762144708
Time: 3.80 s
Epoch 2: 90.03% done
Loss: 260.06695990100366
Time: 4.31 s

Epoch 2 done
Epoch loss: 257.36849413757744

Time taken for epoch: 4.81 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 200.31154089503818

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_2.pt

Regenerated paired data
Epoch 3: 0.05% done
Loss: 13.605904579162598
Time: 0.00 s
Epoch 3: 10.02% done
Loss: 228.84246613186556
Time: 0.49 s
Epoch 3: 20.04% done
Loss: 231.66419927099156
Time: 0.98 s
Epoch 3: 30.01% done
Loss: 254.82701791046952
Time: 1.47 s
Epoch 3: 40.03% done
Loss: 244.08524814275427
Time: 1.94 s
Epoch 3: 50.05% done
Loss: 236.6539889280129
Time: 2.42 s
Epoch 3: 60.02% done
Loss: 240.8005528804344
Time: 2.96 s
Epoch 3: 70.04% done
Loss: 234.50447306412894
Time: 3.44 s
Epoch 3: 80.01% done
Loss: 221.0184709988706
Time: 3.93 s
Epoch 3: 90.03% done
Loss: 252.4174318264384
Time: 4.42 s

Epoch 3 done
Epoch loss: 235.52152504010283

Time taken for epoch: 4.93 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.00 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 172.60013065404362

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_3.pt

Regenerated paired data
Epoch 4: 0.05% done
Loss: 451.23291015625
Time: 0.00 s
Epoch 4: 10.02% done
Loss: 213.98531204338448
Time: 0.41 s
Epoch 4: 20.05% done
Loss: 240.66604763064362
Time: 0.84 s
Epoch 4: 30.02% done
Loss: 225.26291688165975
Time: 1.32 s
Epoch 4: 40.05% done
Loss: 199.88879515456225
Time: 1.79 s
Epoch 4: 50.02% done
Loss: 232.82256988714093
Time: 2.28 s
Epoch 4: 60.05% done
Loss: 215.5341112746968
Time: 2.83 s
Epoch 4: 70.02% done
Loss: 229.93697646902316
Time: 3.31 s
Epoch 4: 80.05% done
Loss: 222.6892644906878
Time: 3.81 s
Epoch 4: 90.02% done
Loss: 241.90564030257786
Time: 4.25 s

Epoch 4 done
Epoch loss: 226.33667729867773

Time taken for epoch: 4.77 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 236.16276048123837

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_4.pt

Regenerated paired data
Epoch 5: 0.05% done
Loss: 422.72634506225586
Time: 0.00 s
Epoch 5: 10.01% done
Loss: 218.44025435793097
Time: 0.50 s
Epoch 5: 20.03% done
Loss: 209.1908498333955
Time: 0.98 s
Epoch 5: 30.04% done
Loss: 215.03470620362583
Time: 1.47 s
Epoch 5: 40.01% done
Loss: 228.9408390869468
Time: 1.93 s
Epoch 5: 50.02% done
Loss: 234.84784271995272
Time: 2.42 s
Epoch 5: 60.04% done
Loss: 217.57401717279893
Time: 2.96 s
Epoch 5: 70.00% done
Loss: 211.16307962059219
Time: 3.46 s
Epoch 5: 80.02% done
Loss: 221.86153759034949
Time: 3.94 s
Epoch 5: 90.03% done
Loss: 211.68888013621947
Time: 4.42 s

Epoch 5 done
Epoch loss: 217.35294877012893

Time taken for epoch: 4.85 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 211.76332210501036

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_5.pt

Regenerated paired data
Epoch 6: 0.05% done
Loss: 39.5382821559906
Time: 0.00 s
Epoch 6: 10.01% done
Loss: 186.68286889954578
Time: 0.42 s
Epoch 6: 20.03% done
Loss: 188.38091265290566
Time: 0.84 s
Epoch 6: 30.04% done
Loss: 212.81516175170285
Time: 1.30 s
Epoch 6: 40.01% done
Loss: 195.31404227018356
Time: 1.80 s
Epoch 6: 50.02% done
Loss: 199.43337556863324
Time: 2.28 s
Epoch 6: 60.04% done
Loss: 203.01688569982392
Time: 2.82 s
Epoch 6: 70.00% done
Loss: 195.64705665313429
Time: 3.28 s
Epoch 6: 80.02% done
Loss: 221.4449082791737
Time: 3.74 s
Epoch 6: 90.03% done
Loss: 186.38185609661795
Time: 4.25 s

Epoch 6 done
Epoch loss: 199.1283294672919

Time taken for epoch: 4.78 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 166.94205709629588

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_6.pt

Regenerated paired data
Epoch 7: 0.05% done
Loss: 7.3895081877708435
Time: 0.00 s
Epoch 7: 10.01% done
Loss: 175.1205360448237
Time: 0.49 s
Epoch 7: 20.03% done
Loss: 209.27543792053373
Time: 0.97 s
Epoch 7: 30.04% done
Loss: 195.8998787345006
Time: 1.45 s
Epoch 7: 40.01% done
Loss: 201.9181085381365
Time: 1.93 s
Epoch 7: 50.02% done
Loss: 211.0380877663783
Time: 2.38 s
Epoch 7: 60.04% done
Loss: 208.34585212324873
Time: 2.88 s
Epoch 7: 70.00% done
Loss: 196.252280840015
Time: 3.34 s
Epoch 7: 80.02% done
Loss: 178.6439291624472
Time: 3.75 s
Epoch 7: 90.03% done
Loss: 213.83704219115984
Time: 4.16 s

Epoch 7 done
Epoch loss: 199.86117129790784

Time taken for epoch: 4.69 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 244.60138525399896

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_7.pt

Regenerated paired data
Epoch 8: 0.05% done
Loss: 150.9275197982788
Time: 0.00 s
Epoch 8: 10.02% done
Loss: 183.250464682257
Time: 0.48 s
Epoch 8: 20.05% done
Loss: 165.54500090317168
Time: 0.98 s
Epoch 8: 30.02% done
Loss: 171.69556209757442
Time: 1.49 s
Epoch 8: 40.05% done
Loss: 199.14898662357976
Time: 1.97 s
Epoch 8: 50.02% done
Loss: 186.68893390433854
Time: 2.43 s
Epoch 8: 60.05% done
Loss: 194.4619720724813
Time: 2.88 s
Epoch 8: 70.02% done
Loss: 182.10772906734783
Time: 3.37 s
Epoch 8: 80.05% done
Loss: 194.2616509470166
Time: 3.77 s
Epoch 8: 90.02% done
Loss: 194.3548627455251
Time: 4.22 s

Epoch 8 done
Epoch loss: 186.92852801836

Time taken for epoch: 4.70 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 193.59710460735693

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_8.pt

Regenerated paired data
Epoch 9: 0.05% done
Loss: 99.98202323913574
Time: 0.00 s
Epoch 9: 10.01% done
Loss: 197.57245462473637
Time: 0.49 s
Epoch 9: 20.03% done
Loss: 156.6335754114451
Time: 0.97 s
Epoch 9: 30.04% done
Loss: 177.8650568996838
Time: 1.46 s
Epoch 9: 40.01% done
Loss: 169.88317436680268
Time: 1.95 s
Epoch 9: 50.02% done
Loss: 159.60949843732317
Time: 2.40 s
Epoch 9: 60.04% done
Loss: 198.70050412713798
Time: 2.97 s
Epoch 9: 70.00% done
Loss: 163.99822133134037
Time: 3.39 s
Epoch 9: 80.02% done
Loss: 168.96911251268972
Time: 3.79 s
Epoch 9: 90.03% done
Loss: 161.37328155407118
Time: 4.26 s

Epoch 9 done
Epoch loss: 177.56133754607197

Time taken for epoch: 4.75 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.00 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 246.19490202102395

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_9.pt

Regenerated paired data
Epoch 10: 0.05% done
Loss: 607.5623512268066
Time: 0.00 s
Epoch 10: 10.01% done
Loss: 181.9484507913963
Time: 0.48 s
Epoch 10: 20.03% done
Loss: 179.74465058714904
Time: 0.94 s
Epoch 10: 30.04% done
Loss: 155.78925883687964
Time: 1.42 s
Epoch 10: 40.01% done
Loss: 156.317941348974
Time: 1.91 s
Epoch 10: 50.02% done
Loss: 186.17023582988924
Time: 2.38 s
Epoch 10: 60.04% done
Loss: 167.9707157305963
Time: 2.89 s
Epoch 10: 70.00% done
Loss: 177.02699975509728
Time: 3.37 s
Epoch 10: 80.02% done
Loss: 196.44049046851626
Time: 3.80 s
Epoch 10: 90.03% done
Loss: 176.04903161670978
Time: 4.22 s

Epoch 10 done
Epoch loss: 176.32454499000403

Time taken for epoch: 4.70 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 209.7365809397565

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_10.pt

Regenerated paired data
Epoch 11: 0.05% done
Loss: 375.2288341522217
Time: 0.00 s
Epoch 11: 10.01% done
Loss: 154.8227083338167
Time: 0.47 s
Epoch 11: 20.03% done
Loss: 179.0992896790283
Time: 0.97 s
Epoch 11: 30.04% done
Loss: 180.44167764937728
Time: 1.46 s
Epoch 11: 40.01% done
Loss: 155.37839551812493
Time: 1.90 s
Epoch 11: 50.02% done
Loss: 175.65360481577386
Time: 2.31 s
Epoch 11: 60.04% done
Loss: 205.39632932808456
Time: 2.87 s
Epoch 11: 70.00% done
Loss: 175.66585462703478
Time: 3.33 s
Epoch 11: 80.02% done
Loss: 193.1043093242264
Time: 3.84 s
Epoch 11: 90.03% done
Loss: 170.29448786383034
Time: 4.32 s

Epoch 11 done
Epoch loss: 174.5666721463011

Time taken for epoch: 4.84 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 227.447705819375

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_11.pt

Regenerated paired data
Epoch 12: 0.05% done
Loss: 263.11914920806885
Time: 0.00 s
Epoch 12: 10.02% done
Loss: 162.506593365763
Time: 0.46 s
Epoch 12: 20.04% done
Loss: 171.06470978827377
Time: 0.88 s
Epoch 12: 30.01% done
Loss: 174.2176527895617
Time: 1.32 s
Epoch 12: 40.03% done
Loss: 156.29211525334506
Time: 1.78 s
Epoch 12: 50.05% done
Loss: 191.47141412169665
Time: 2.22 s
Epoch 12: 60.02% done
Loss: 188.0680912908184
Time: 2.76 s
Epoch 12: 70.04% done
Loss: 155.8874268734127
Time: 3.25 s
Epoch 12: 80.01% done
Loss: 151.4581461582968
Time: 3.70 s
Epoch 12: 90.03% done
Loss: 164.30688472037468
Time: 4.11 s

Epoch 12 done
Epoch loss: 168.55496494173326

Time taken for epoch: 4.56 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.00 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 182.99854815834098

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_12.pt

Regenerated paired data
Epoch 13: 0.05% done
Loss: 58.292001485824585
Time: 0.00 s
Epoch 13: 10.02% done
Loss: 168.09301791961568
Time: 0.41 s
Epoch 13: 20.05% done
Loss: 174.8134363814334
Time: 0.87 s
Epoch 13: 30.02% done
Loss: 183.64801357332874
Time: 1.37 s
Epoch 13: 40.05% done
Loss: 161.85775034197974
Time: 1.85 s
Epoch 13: 50.02% done
Loss: 163.7886155152067
Time: 2.34 s
Epoch 13: 60.05% done
Loss: 165.38068794115625
Time: 2.86 s
Epoch 13: 70.02% done
Loss: 151.05030601543766
Time: 3.37 s
Epoch 13: 80.05% done
Loss: 154.90321688796715
Time: 3.87 s
Epoch 13: 90.02% done
Loss: 156.9614690423767
Time: 4.34 s

Epoch 13 done
Epoch loss: 162.93640622813737

Time taken for epoch: 4.84 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 258.2173862391048

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_13.pt

Regenerated paired data
Epoch 14: 0.05% done
Loss: 200.28045177459717
Time: 0.00 s
Epoch 14: 10.03% done
Loss: 129.82207772832723
Time: 0.48 s
Epoch 14: 20.02% done
Loss: 147.89377909394042
Time: 0.96 s
Epoch 14: 30.00% done
Loss: 143.0737792973488
Time: 1.45 s
Epoch 14: 40.04% done
Loss: 176.5267400147923
Time: 1.92 s
Epoch 14: 50.02% done
Loss: 137.0579039673686
Time: 2.36 s
Epoch 14: 60.01% done
Loss: 146.255244533982
Time: 2.87 s
Epoch 14: 70.04% done
Loss: 195.14193201604206
Time: 3.33 s
Epoch 14: 80.03% done
Loss: 230.12243430602283
Time: 3.83 s
Epoch 14: 90.01% done
Loss: 209.8105236767761
Time: 4.30 s

Epoch 14 done
Epoch loss: 170.3217297618428

Time taken for epoch: 4.80 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.00 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 259.2127093838321

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_14.pt

Regenerated paired data
Epoch 15: 0.05% done
Loss: 40.79555571079254
Time: 0.00 s
Epoch 15: 10.01% done
Loss: 168.96833813865132
Time: 0.46 s
Epoch 15: 20.03% done
Loss: 174.40393058104664
Time: 0.90 s
Epoch 15: 30.04% done
Loss: 161.3129245582968
Time: 1.34 s
Epoch 15: 40.01% done
Loss: 141.438235409884
Time: 1.73 s
Epoch 15: 50.02% done
Loss: 161.75173936398923
Time: 2.18 s
Epoch 15: 60.04% done
Loss: 137.89560600149727
Time: 2.69 s
Epoch 15: 70.00% done
Loss: 162.4168921974466
Time: 3.11 s
Epoch 15: 80.02% done
Loss: 171.74815095516794
Time: 3.52 s
Epoch 15: 90.03% done
Loss: 164.6613360365528
Time: 3.93 s

Epoch 15 done
Epoch loss: 161.53881830457627

Time taken for epoch: 4.40 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 170.14178509513536

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_15.pt

Regenerated paired data
Epoch 16: 0.05% done
Loss: 64.15224075317383
Time: 0.00 s
Epoch 16: 10.02% done
Loss: 154.46203698142332
Time: 0.50 s
Epoch 16: 20.04% done
Loss: 169.67000549556602
Time: 0.99 s
Epoch 16: 30.01% done
Loss: 170.29141637846433
Time: 1.50 s
Epoch 16: 40.03% done
Loss: 153.95113990103843
Time: 1.98 s
Epoch 16: 50.05% done
Loss: 183.3644204046748
Time: 2.46 s
Epoch 16: 60.02% done
Loss: 176.83703086557819
Time: 3.00 s
Epoch 16: 70.04% done
Loss: 180.56358481680445
Time: 3.52 s
Epoch 16: 80.01% done
Loss: 160.30178956799037
Time: 4.01 s
Epoch 16: 90.03% done
Loss: 169.52619422867963
Time: 4.49 s

Epoch 16 done
Epoch loss: 169.87263681813226

Time taken for epoch: 5.03 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 183.13482319936156

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_mean_512_proj_lr_0.0005_linear_weight_decay_0.05/2024-07-22_21:28:10_checkpoint_epoch_16.pt

Regenerated paired data
Validation loss has not improved for 10 epochs. Stopping training.
BEST VALIDATION LOSS: 166.94205709629588 at epoch 6

