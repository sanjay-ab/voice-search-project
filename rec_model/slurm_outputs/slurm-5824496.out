Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
Training reference file: data/tamil/analysis/ref_of_queries_in_docs_train.txt
Validation reference file: data/tamil/analysis/ref_of_queries_in_docs_valid.txt
START TIME: 2024-07-22_20:07:42
Training model for tamil with inputs from mHuBERT layer 9
Number of epochs: 100, patience: 10, learning rate: 0.001
clip norm: 20, temperature: 0.15, num pairs per batch: 2
time limit to create dataset: 600
temperature: 0.15

Created paired data
Created paired data
Time taken to create datasets: 47.15 s
Number of parameters in model: 6039552
Epoch 0: 0.05% done
Loss: 458.8364601135254
Time: 0.54 s
Epoch 0: 10.01% done
Loss: 439.49088028499057
Time: 1.00 s
Epoch 0: 20.03% done
Loss: 433.3508078111421
Time: 1.56 s
Epoch 0: 30.04% done
Loss: 419.167965486509
Time: 2.04 s
Epoch 0: 40.01% done
Loss: 354.4474928609786
Time: 2.59 s
Epoch 0: 50.02% done
Loss: 339.3181628863746
Time: 3.10 s
Epoch 0: 60.04% done
Loss: 313.0681295323809
Time: 3.76 s
Epoch 0: 70.00% done
Loss: 276.4439389418622
Time: 4.33 s
Epoch 0: 80.02% done
Loss: 289.54789434140974
Time: 4.88 s
Epoch 0: 90.03% done
Loss: 285.81927987413667
Time: 5.44 s

Epoch 0 done
Epoch loss: 340.38144212539555

Time taken for epoch: 6.02 s
Number of gradients clipped: 18

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 194.45994546016058

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_0.pt

Regenerated paired data
Epoch 1: 0.05% done
Loss: 170.09574174880981
Time: 0.00 s
Epoch 1: 10.01% done
Loss: 200.0570522509687
Time: 0.48 s
Epoch 1: 20.03% done
Loss: 182.80581623623405
Time: 1.03 s
Epoch 1: 30.04% done
Loss: 160.709955618469
Time: 1.60 s
Epoch 1: 40.01% done
Loss: 154.15543703928864
Time: 2.20 s
Epoch 1: 50.02% done
Loss: 178.62641077078538
Time: 2.70 s
Epoch 1: 60.04% done
Loss: 150.2027588845188
Time: 3.24 s
Epoch 1: 70.00% done
Loss: 165.3376718871467
Time: 3.70 s
Epoch 1: 80.02% done
Loss: 153.7507794532549
Time: 4.20 s
Epoch 1: 90.03% done
Loss: 139.50762517852795
Time: 4.68 s

Epoch 1 done
Epoch loss: 162.0722081541731

Time taken for epoch: 5.27 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 175.88402844137616

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_1.pt

Regenerated paired data
Epoch 2: 0.05% done
Loss: 21.991102397441864
Time: 0.00 s
Epoch 2: 10.01% done
Loss: 106.6367325282866
Time: 0.58 s
Epoch 2: 20.03% done
Loss: 86.54965044964754
Time: 1.11 s
Epoch 2: 30.04% done
Loss: 93.51112777025465
Time: 1.67 s
Epoch 2: 40.01% done
Loss: 96.25433894917197
Time: 2.22 s
Epoch 2: 50.02% done
Loss: 77.90694978865666
Time: 2.76 s
Epoch 2: 60.04% done
Loss: 86.5142884574523
Time: 3.32 s
Epoch 2: 70.00% done
Loss: 81.2496296530332
Time: 3.77 s
Epoch 2: 80.02% done
Loss: 78.71302419978647
Time: 4.27 s
Epoch 2: 90.03% done
Loss: 75.84880528717362
Time: 4.80 s

Epoch 2 done
Epoch loss: 87.02504180787156

Time taken for epoch: 5.33 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 135.86554009881286

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_2.pt

Regenerated paired data
Epoch 3: 0.05% done
Loss: 1.8514523282647133
Time: 0.00 s
Epoch 3: 10.02% done
Loss: 73.03718293669381
Time: 0.51 s
Epoch 3: 20.04% done
Loss: 72.29050931695917
Time: 0.99 s
Epoch 3: 30.01% done
Loss: 69.9075420236876
Time: 1.51 s
Epoch 3: 40.03% done
Loss: 72.7324686530089
Time: 2.05 s
Epoch 3: 50.05% done
Loss: 68.71548616968164
Time: 2.57 s
Epoch 3: 60.02% done
Loss: 69.97586782401522
Time: 3.14 s
Epoch 3: 70.04% done
Loss: 57.9382777519507
Time: 3.59 s
Epoch 3: 80.01% done
Loss: 50.1303797998693
Time: 4.11 s
Epoch 3: 90.03% done
Loss: 72.67108199041371
Time: 4.65 s

Epoch 3 done
Epoch loss: 66.32715776707782

Time taken for epoch: 5.25 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 181.0133767210775

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_3.pt

Regenerated paired data
Epoch 4: 0.05% done
Loss: 35.692739486694336
Time: 0.00 s
Epoch 4: 10.02% done
Loss: 52.73055423368713
Time: 0.55 s
Epoch 4: 20.05% done
Loss: 52.936196668018
Time: 1.04 s
Epoch 4: 30.02% done
Loss: 51.18735237304585
Time: 1.50 s
Epoch 4: 40.05% done
Loss: 45.40362141667566
Time: 1.96 s
Epoch 4: 50.02% done
Loss: 52.96629521650292
Time: 2.42 s
Epoch 4: 60.05% done
Loss: 45.629015979314346
Time: 2.98 s
Epoch 4: 70.02% done
Loss: 49.08748789119624
Time: 3.43 s
Epoch 4: 80.05% done
Loss: 53.28290216537158
Time: 3.99 s
Epoch 4: 90.02% done
Loss: 47.75448149308339
Time: 4.52 s

Epoch 4 done
Epoch loss: 50.55228010003037

Time taken for epoch: 5.02 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 168.84715269423194

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_4.pt

Regenerated paired data
Epoch 5: 0.05% done
Loss: 5.447709932923317
Time: 0.00 s
Epoch 5: 10.01% done
Loss: 38.539733605841306
Time: 0.46 s
Epoch 5: 20.03% done
Loss: 36.14392973730392
Time: 0.98 s
Epoch 5: 30.04% done
Loss: 40.820076124029185
Time: 1.44 s
Epoch 5: 40.01% done
Loss: 37.72114348728725
Time: 1.89 s
Epoch 5: 50.02% done
Loss: 38.19339844129057
Time: 2.33 s
Epoch 5: 60.04% done
Loss: 29.01484960772379
Time: 2.85 s
Epoch 5: 70.00% done
Loss: 35.7452078594736
Time: 3.37 s
Epoch 5: 80.02% done
Loss: 34.23146690303938
Time: 3.96 s
Epoch 5: 90.03% done
Loss: 36.2622927919184
Time: 4.73 s

Epoch 5 done
Epoch loss: 36.13571061773699

Time taken for epoch: 5.35 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 146.49152416321965

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_5.pt

Regenerated paired data
Epoch 6: 0.05% done
Loss: 1.652371697127819
Time: 0.00 s
Epoch 6: 10.01% done
Loss: 32.03048450997837
Time: 0.50 s
Epoch 6: 20.03% done
Loss: 36.56996702906193
Time: 0.97 s
Epoch 6: 30.04% done
Loss: 37.042048248171874
Time: 1.52 s
Epoch 6: 40.01% done
Loss: 32.084406621878635
Time: 2.07 s
Epoch 6: 50.02% done
Loss: 29.434876086792713
Time: 2.61 s
Epoch 6: 60.04% done
Loss: 31.74718197727781
Time: 3.19 s
Epoch 6: 70.00% done
Loss: 35.99359590961482
Time: 3.74 s
Epoch 6: 80.02% done
Loss: 42.4045480086058
Time: 4.27 s
Epoch 6: 90.03% done
Loss: 29.550566063358644
Time: 4.80 s

Epoch 6 done
Epoch loss: 33.945238815876046

Time taken for epoch: 5.36 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 220.55299580097198

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_6.pt

Regenerated paired data
Epoch 7: 0.05% done
Loss: 8.917468786239624
Time: 0.00 s
Epoch 7: 10.01% done
Loss: 31.834987358700843
Time: 0.56 s
Epoch 7: 20.03% done
Loss: 27.10233666066832
Time: 1.07 s
Epoch 7: 30.04% done
Loss: 33.75672240957293
Time: 1.54 s
Epoch 7: 40.01% done
Loss: 40.05488653899029
Time: 2.02 s
Epoch 7: 50.02% done
Loss: 38.18272131926662
Time: 2.52 s
Epoch 7: 60.04% done
Loss: 38.91204092170992
Time: 3.14 s
Epoch 7: 70.00% done
Loss: 43.677705415355014
Time: 3.59 s
Epoch 7: 80.02% done
Loss: 38.56762024262117
Time: 4.09 s
Epoch 7: 90.03% done
Loss: 34.28240879935451
Time: 4.59 s

Epoch 7 done
Epoch loss: 36.087820286206735

Time taken for epoch: 5.08 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 255.17679233517913

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_7.pt

Regenerated paired data
Epoch 8: 0.05% done
Loss: 2.2292446345090866
Time: 0.00 s
Epoch 8: 10.02% done
Loss: 27.834654368314258
Time: 0.54 s
Epoch 8: 20.05% done
Loss: 27.892248271409116
Time: 1.01 s
Epoch 8: 30.02% done
Loss: 30.0962393155991
Time: 1.59 s
Epoch 8: 40.05% done
Loss: 31.887173716089936
Time: 2.14 s
Epoch 8: 50.02% done
Loss: 28.111186217890047
Time: 2.60 s
Epoch 8: 60.05% done
Loss: 32.64500484545501
Time: 3.11 s
Epoch 8: 70.02% done
Loss: 29.81457287431716
Time: 3.55 s
Epoch 8: 80.05% done
Loss: 27.11083252429364
Time: 4.10 s
Epoch 8: 90.02% done
Loss: 29.46606408649077
Time: 4.56 s

Epoch 8 done
Epoch loss: 29.89519450280965

Time taken for epoch: 5.12 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 246.53404470947055

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_8.pt

Regenerated paired data
Epoch 9: 0.05% done
Loss: 24.359287321567535
Time: 0.00 s
Epoch 9: 10.01% done
Loss: 35.23974736652462
Time: 0.54 s
Epoch 9: 20.03% done
Loss: 27.036416001079623
Time: 1.01 s
Epoch 9: 30.04% done
Loss: 33.579462976728934
Time: 1.48 s
Epoch 9: 40.01% done
Loss: 35.326974480015906
Time: 1.94 s
Epoch 9: 50.02% done
Loss: 30.48524676646969
Time: 2.48 s
Epoch 9: 60.04% done
Loss: 37.86530527291572
Time: 3.07 s
Epoch 9: 70.00% done
Loss: 27.756530522853822
Time: 3.62 s
Epoch 9: 80.02% done
Loss: 33.22051358467968
Time: 4.16 s
Epoch 9: 90.03% done
Loss: 24.680476791947363
Time: 4.67 s

Epoch 9 done
Epoch loss: 31.474450187109813

Time taken for epoch: 5.18 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 257.3350257343716

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_9.pt

Regenerated paired data
Epoch 10: 0.05% done
Loss: 51.52658224105835
Time: 0.00 s
Epoch 10: 10.01% done
Loss: 19.909440941436962
Time: 0.47 s
Epoch 10: 20.03% done
Loss: 24.755815114415306
Time: 0.94 s
Epoch 10: 30.04% done
Loss: 22.036216658841255
Time: 1.41 s
Epoch 10: 40.01% done
Loss: 28.300490799093886
Time: 1.88 s
Epoch 10: 50.02% done
Loss: 31.927270651047348
Time: 2.41 s
Epoch 10: 60.04% done
Loss: 28.580913101397712
Time: 3.03 s
Epoch 10: 70.00% done
Loss: 29.826756038441225
Time: 3.55 s
Epoch 10: 80.02% done
Loss: 27.439318502902847
Time: 4.09 s
Epoch 10: 90.03% done
Loss: 28.189002919019362
Time: 4.56 s

Epoch 10 done
Epoch loss: 27.115309714981322

Time taken for epoch: 5.09 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 269.741457566205

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_10.pt

Regenerated paired data
Epoch 11: 0.05% done
Loss: 7.665133476257324
Time: 0.00 s
Epoch 11: 10.01% done
Loss: 21.771903031276032
Time: 0.49 s
Epoch 11: 20.03% done
Loss: 26.407462324618166
Time: 1.01 s
Epoch 11: 30.04% done
Loss: 26.508549773273135
Time: 1.54 s
Epoch 11: 40.01% done
Loss: 24.41018436110497
Time: 2.04 s
Epoch 11: 50.02% done
Loss: 22.379007221946125
Time: 2.58 s
Epoch 11: 60.04% done
Loss: 28.34760105490221
Time: 3.15 s
Epoch 11: 70.00% done
Loss: 24.77999165641307
Time: 3.63 s
Epoch 11: 80.02% done
Loss: 21.147801298963188
Time: 4.14 s
Epoch 11: 90.03% done
Loss: 18.719386778197276
Time: 4.72 s

Epoch 11 done
Epoch loss: 23.397635485325125

Time taken for epoch: 5.32 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.01 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 323.5261711188489

Time taken: 0.02 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_11.pt

Regenerated paired data
Epoch 12: 0.05% done
Loss: 10.301545262336731
Time: 0.00 s
Epoch 12: 10.02% done
Loss: 23.257710645753196
Time: 0.48 s
Epoch 12: 20.04% done
Loss: 28.5752718680519
Time: 0.98 s
Epoch 12: 30.01% done
Loss: 24.923465041575678
Time: 1.48 s
Epoch 12: 40.03% done
Loss: 21.838044883937513
Time: 2.01 s
Epoch 12: 50.05% done
Loss: 23.566514668546173
Time: 2.54 s
Epoch 12: 60.02% done
Loss: 22.868037023817614
Time: 3.09 s
Epoch 12: 70.04% done
Loss: 27.398291490774458
Time: 3.58 s
Epoch 12: 80.01% done
Loss: 26.489907268634333
Time: 4.15 s
Epoch 12: 90.03% done
Loss: 21.29100816670929
Time: 4.71 s

Epoch 12 done
Epoch loss: 24.83963295254291

Time taken for epoch: 5.32 s
Number of gradients clipped: 22

Calculating validation loss: 5.56% done
Time: 0.00 s
Calculating validation loss: 22.22% done
Time: 0.01 s
Calculating validation loss: 44.44% done
Time: 0.01 s
Calculating validation loss: 61.11% done
Time: 0.02 s
Calculating validation loss: 83.33% done
Time: 0.02 s

Validation loss: 250.84178596735

Time taken: 0.03 s
Saving model to data/tamil/models/sent/9/awe2_512_proj_lr_0.001_linear_weight_decay_0.01/2024-07-22_20:07:42_checkpoint_epoch_12.pt

Regenerated paired data
Validation loss has not improved for 10 epochs. Stopping training.
BEST VALIDATION LOSS: 135.86554009881286 at epoch 2

