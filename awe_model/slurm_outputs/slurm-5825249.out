Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
Training embeddings directory: data/tamil/embeddings/training_data/9/raw
Validation embeddings file: data/tamil/embeddings/validation_data/9/phonetized_3_9/all_embeddings_phonetized.pkl
START TIME: 2024-07-23_12:57:16
Training model for tamil with inputs from mHuBERT layer 9
Number of epochs: 3, patience: 2, learning rate: 0.0001
clip norm: 40, temperature: 0.07, num pairs per batch: 5
num batch pairs to accumulate gradients over: 1000
time limit to create dataset: 600
temperature: 0.07
min phone seq length: 3, max phone seq length: 9
perturb sequences: False, max one sided perturb amount: 0.1

Model save directory: data/tamil/models/awe/9/mpr_lr_0.0001_tmp_0.07_acc_1000_bs_5_3_9

Loading embedded data from directory: data/tamil/embeddings/training_data/9/raw
Loaded embedded data from data/tamil/embeddings/training_data/9/raw
Time taken: 111.99 s
Created paired data
Loading embedded data from file: data/tamil/embeddings/validation_data/9/phonetized_3_9/all_embeddings_phonetized.pkl
Loaded embedded data from data/tamil/embeddings/validation_data/9/phonetized_3_9/all_embeddings_phonetized.pkl
Time taken: 18.42 s
Created paired data
Time taken to create datasets: 216.15 s
/work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch 0: 0.00% done
Loss: 343.3866882324219
Time: 16.43 s
Epoch 0: 10.00% done
Loss: 43.902615139808184
Time: 150.25 s
Epoch 0: 20.00% done
Loss: 10.406438323508498
Time: 282.49 s
Epoch 0: 30.00% done
Loss: 7.539302590889616
Time: 406.14 s
Epoch 0: 40.00% done
Loss: 6.261781274595186
Time: 543.22 s
Epoch 0: 50.00% done
Loss: 5.354146775891248
Time: 667.34 s
Epoch 0: 60.00% done
Loss: 4.607072917719087
Time: 785.65 s
Epoch 0: 70.00% done
Loss: 4.011425521282987
Time: 905.85 s
Epoch 0: 80.00% done
Loss: 3.5654069140927747
Time: 1024.80 s
Epoch 0: 90.00% done
Loss: 3.382961831260448
Time: 1142.54 s

Epoch 0 done
Epoch loss: 9.201679588591855

Time taken for epoch: 1256.20 s
Number of gradients clipped: 1176

Calculating validation loss: 0.00% done
Time: 0.01 s
Calculating validation loss: 20.00% done
Time: 51.35 s
Calculating validation loss: 40.00% done
Time: 103.55 s
Calculating validation loss: 60.00% done
Time: 154.85 s
Calculating validation loss: 80.00% done
Time: 208.80 s

Validation loss: 100.0857447043418

Time taken: 260.74 s
Saving model to data/tamil/models/awe/9/mpr_lr_0.0001_tmp_0.07_acc_1000_bs_5_3_9/2024-07-23_12:57:16_checkpoint_epoch_0.pt

Regenerated paired data
Epoch 1: 0.00% done
Loss: 0.13825269415974617
Time: 0.15 s
Epoch 1: 10.00% done
Loss: 2.7408544828701102
Time: 115.26 s
Epoch 1: 20.00% done
Loss: 2.4219427604467536
Time: 228.21 s
Epoch 1: 30.00% done
Loss: 2.4280853067316555
Time: 343.80 s
Epoch 1: 40.00% done
Loss: 2.211416678051171
Time: 457.25 s
Epoch 1: 50.00% done
Loss: 2.073490791072684
Time: 572.69 s
Epoch 1: 60.00% done
Loss: 1.9762119396547482
Time: 685.15 s
Epoch 1: 70.00% done
Loss: 1.866408007701506
Time: 802.20 s
Epoch 1: 80.00% done
Loss: 1.9146339221835293
Time: 915.63 s
Epoch 1: 90.00% done
Loss: 1.6924099584890995
Time: 1030.76 s

Epoch 1 done
Epoch loss: 2.0985054108365286

Time taken for epoch: 1148.40 s
Number of gradients clipped: 404

Calculating validation loss: 0.00% done
Time: 0.07 s
Calculating validation loss: 20.00% done
Time: 50.97 s
Calculating validation loss: 40.00% done
Time: 101.85 s
Calculating validation loss: 60.00% done
Time: 152.68 s
Calculating validation loss: 80.00% done
Time: 203.60 s

Validation loss: 99.12116605045306

Time taken: 254.44 s
Saving model to data/tamil/models/awe/9/mpr_lr_0.0001_tmp_0.07_acc_1000_bs_5_3_9/2024-07-23_12:57:16_checkpoint_epoch_1.pt

Regenerated paired data
Epoch 2: 0.00% done
Loss: 0.00036954857023374643
Time: 0.02 s
Epoch 2: 10.00% done
Loss: 1.523301705001001
Time: 112.78 s
Epoch 2: 20.00% done
Loss: 1.3862657646294203
Time: 227.11 s
Epoch 2: 30.00% done
Loss: 1.4527471807498018
Time: 340.39 s
Epoch 2: 40.00% done
Loss: 1.25711124169991
Time: 458.60 s
Epoch 2: 50.00% done
Loss: 1.3537965845660624
Time: 572.20 s
Epoch 2: 60.00% done
Loss: 1.2482059550525668
Time: 686.17 s
Epoch 2: 70.00% done
Loss: 1.2220719779894502
Time: 798.72 s
Epoch 2: 80.00% done
Loss: 1.2120662575031298
Time: 911.83 s
Epoch 2: 90.00% done
Loss: 1.1794354724571452
Time: 1027.84 s

Epoch 2 done
Epoch loss: 1.2971902552710275

Time taken for epoch: 1139.51 s
Number of gradients clipped: 90

Calculating validation loss: 0.00% done
Time: 0.01 s
Calculating validation loss: 20.00% done
Time: 51.06 s
Calculating validation loss: 40.00% done
Time: 102.03 s
Calculating validation loss: 60.00% done
Time: 152.96 s
Calculating validation loss: 80.00% done
Time: 203.77 s

Validation loss: 95.94583727907568

Time taken: 254.75 s
Saving model to data/tamil/models/awe/9/mpr_lr_0.0001_tmp_0.07_acc_1000_bs_5_3_9/2024-07-23_12:57:16_checkpoint_epoch_2.pt

Regenerated paired data
BEST VALIDATION LOSS: 95.94583727907568 at epoch 2

