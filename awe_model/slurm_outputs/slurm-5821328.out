Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
Training embeddings directory: data/tamil/embeddings/training_data_quarter/9/raw
Validation embeddings file: data/tamil/embeddings/validation_data/9/phonetized_3_9/all_embeddings_phonetized.pkl
START TIME: 2024-07-20_19:10:55
Training model for tamil with inputs from mHuBERT layer 9
Number of epochs: 3, patience: 2, learning rate: 0.0001
clip norm: 40, temperature: 0.07, num pairs per batch: 700
num batch pairs to accumulate gradients over: 1000
time limit to create dataset: 600
temperature: 0.07
min phone seq length: 3, max phone seq length: 9
perturb sequences: False, max one sided perturb amount: 0.1

Loading embedded data from directory: data/tamil/embeddings/training_data_quarter/9/raw
Loaded embedded data from data/tamil/embeddings/training_data_quarter/9/raw
Time taken: 6.84 s
Created paired data
Loading embedded data from file: data/tamil/embeddings/validation_data/9/phonetized_3_9/all_embeddings_phonetized.pkl
Loaded embedded data from data/tamil/embeddings/validation_data/9/phonetized_3_9/all_embeddings_phonetized.pkl
Time taken: 19.04 s
Created paired data
Time taken to create datasets: 48.57 s
/work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch 0: 0.00% done
Loss: 377.4866580963135
Time: 0.54 s
Epoch 0: 10.00% done
Loss: 30.203359684031156
Time: 54.38 s
Epoch 0: 20.00% done
Loss: 2.0668188556684526
Time: 109.22 s
Epoch 0: 30.00% done
Loss: 0.9218215476046202
Time: 165.55 s
Epoch 0: 40.00% done
Loss: 0.5296345818484985
Time: 216.01 s
Epoch 0: 50.00% done
Loss: 0.36758998500252504
Time: 268.18 s
Epoch 0: 60.00% done
Loss: 0.2628522137071728
Time: 322.98 s
Epoch 0: 70.00% done
Loss: 0.19318116005811342
Time: 378.25 s
Epoch 0: 80.00% done
Loss: 0.16116385258298802
Time: 434.41 s
Epoch 0: 90.00% done
Loss: 0.13134294936537189
Time: 489.81 s

Epoch 0 done
Epoch loss: 3.4991378718566186

Time taken for epoch: 546.89 s
Number of gradients clipped: 70

Calculating validation loss: 0.00% done
Time: 0.01 s
Calculating validation loss: 20.00% done
Time: 45.48 s
Calculating validation loss: 40.00% done
Time: 90.22 s
Calculating validation loss: 60.00% done
Time: 141.00 s
Calculating validation loss: 80.00% done
Time: 190.28 s

Validation loss: 35.08141348009536

Time taken: 236.47 s
Saving model to data/tamil/models/awe/9/quarter_lr_1e-4_tmp_0.07_acc_1000_3_9/2024-07-20_19:10:55_checkpoint_epoch_0.pt

Regenerated paired data
Epoch 1: 0.00% done
Loss: 0.0001192092668134137
Time: 0.01 s
Epoch 1: 10.00% done
Loss: 0.09179722174702634
Time: 57.38 s
Epoch 1: 20.00% done
Loss: 0.07029366822954654
Time: 110.91 s
Epoch 1: 30.00% done
Loss: 0.05798508440451284
Time: 165.40 s
Epoch 1: 40.00% done
Loss: 0.06134689192330536
Time: 220.72 s
Epoch 1: 50.00% done
Loss: 0.047799681489834066
Time: 272.92 s
Epoch 1: 60.00% done
Loss: 0.04357485691691069
Time: 328.03 s
Epoch 1: 70.00% done
Loss: 0.04055111491381341
Time: 383.60 s
Epoch 1: 80.00% done
Loss: 0.03499711691950629
Time: 438.53 s
Epoch 1: 90.00% done
Loss: 0.033475137126367335
Time: 496.28 s

Epoch 1 done
Epoch loss: 0.051195501932922105

Time taken for epoch: 552.32 s
Number of gradients clipped: 0

Calculating validation loss: 0.00% done
Time: 0.01 s
Calculating validation loss: 20.00% done
Time: 46.89 s
Calculating validation loss: 40.00% done
Time: 89.89 s
Calculating validation loss: 60.00% done
Time: 136.37 s
Calculating validation loss: 80.00% done
Time: 188.66 s

Validation loss: 39.42308986204356

Time taken: 237.98 s
Saving model to data/tamil/models/awe/9/quarter_lr_1e-4_tmp_0.07_acc_1000_3_9/2024-07-20_19:10:55_checkpoint_epoch_1.pt

Regenerated paired data
Epoch 2: 0.00% done
Loss: 0.4429281875491142
Time: 0.03 s
Epoch 2: 10.00% done
Loss: 0.028980221786997315
Time: 58.21 s
Epoch 2: 20.00% done
Loss: 0.0225417812923508
Time: 113.26 s
Epoch 2: 30.00% done
Loss: 0.021735323557245827
Time: 167.13 s
Epoch 2: 40.00% done
Loss: 0.01797179240323705
Time: 217.54 s
Epoch 2: 50.00% done
Loss: 0.020834555765223264
Time: 275.58 s
Epoch 2: 60.00% done
Loss: 0.017371918731682607
Time: 330.46 s
Epoch 2: 70.00% done
Loss: 0.015592296836552149
Time: 385.67 s
Epoch 2: 80.00% done
Loss: 0.01399951125120173
Time: 440.00 s
Epoch 2: 90.00% done
Loss: 0.01283479124805914
Time: 491.09 s

Epoch 2 done
Epoch loss: 0.01863653405072432

Time taken for epoch: 548.59 s
Number of gradients clipped: 0

Calculating validation loss: 0.00% done
Time: 0.01 s
Calculating validation loss: 20.00% done
Time: 44.79 s
Calculating validation loss: 40.00% done
Time: 90.05 s
Calculating validation loss: 60.00% done
Time: 135.26 s
Calculating validation loss: 80.00% done
Time: 186.37 s

Validation loss: 43.580942216870525

Time taken: 231.53 s
Saving model to data/tamil/models/awe/9/quarter_lr_1e-4_tmp_0.07_acc_1000_3_9/2024-07-20_19:10:55_checkpoint_epoch_2.pt

Regenerated paired data
Validation loss has not improved for 2 epochs. Stopping training.
BEST VALIDATION LOSS: 35.08141348009536 at epoch 0

