Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
START TIME: 2024-07-10_22:09:02
Training model for tamil with inputs from mHuBERT layer 8
Number of epochs: 10, patience: 2, learning rate: 0.0001
clip norm: 20, temperature: 0.15, num pairs per batch: 800
time limit to create dataset: 240
Loaded embedded data from data/tamil/embeddings/training_data/8/raw_full_utterances/all_embeddings_phonetized.pkl
Time taken: 63.99 s
Dataset generation time limit reached: 240 s.
Number of classes remaining: 260.
Created paired data
Loaded embedded data from data/tamil/embeddings/validation_data/8/raw_full_utterances/all_embeddings_phonetized.pkl
Time taken: 12.20 s
Created paired data
Time taken to create datasets: 442.02 s
/work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch 0: 0.01% done
Loss: 6.348848342895508
Time: 4.96 s
Epoch 0: 10.00% done
Loss: 2.9266835783803185
Time: 249.68 s
Epoch 0: 20.01% done
Loss: 2.0121843892402365
Time: 488.23 s
Epoch 0: 30.00% done
Loss: 1.6745516792563504
Time: 737.72 s
Epoch 0: 40.01% done
Loss: 1.4734324992367769
Time: 991.04 s
Epoch 0: 50.00% done
Loss: 1.358269121924112
Time: 1253.78 s
Epoch 0: 60.01% done
Loss: 1.254137575515584
Time: 1505.52 s
Epoch 0: 70.00% done
Loss: 1.1538807877274446
Time: 1746.02 s
Epoch 0: 80.01% done
Loss: 1.1346000052960832
Time: 1992.62 s
Epoch 0: 90.00% done
Loss: 1.0839986839959788
Time: 2247.89 s

Epoch 0 done
Epoch loss: 1.5123152983016825

Time taken for epoch: 2495.22 s
Number of gradients clipped: 0

Calculating validation loss: 0.00% done
Time: 0.02 s
Calculating validation loss: 20.00% done
Time: 143.04 s
Calculating validation loss: 40.00% done
Time: 294.98 s
Calculating validation loss: 60.00% done
Time: 446.81 s
Calculating validation loss: 80.00% done
Time: 598.54 s

Validation loss: 1.1453007640266233

Time taken: 751.53 s
Saving model to data/tamil/models/8/phones_split_after_embedding2024-07-10_22:09:02_checkpoint_epoch_0.pt

Dataset generation time limit reached: 240 s.
Number of classes remaining: 259.
Epoch 1: 0.01% done
Loss: 0.8697608709335327
Time: 7.54 s
Epoch 1: 10.01% done
Loss: 1.0107928966748736
Time: 259.29 s
Epoch 1: 20.01% done
Loss: 1.008924259881656
Time: 520.34 s
Epoch 1: 30.01% done
Loss: 0.976862270267966
Time: 770.60 s
Epoch 1: 40.01% done
Loss: 0.9527718079398608
Time: 1019.96 s
Epoch 1: 50.01% done
Loss: 0.9516373203995047
Time: 1277.44 s
Epoch 1: 60.01% done
Loss: 0.9420272677090163
Time: 1527.51 s
Epoch 1: 70.01% done
Loss: 0.9420001007162049
Time: 1780.26 s
Epoch 1: 80.01% done
Loss: 0.9157394087579026
Time: 2025.80 s
Epoch 1: 90.01% done
Loss: 0.9004108842992519
Time: 2270.66 s

Epoch 1 done
Epoch loss: 0.9511262365993863

Time taken for epoch: 2519.32 s
Number of gradients clipped: 0

Calculating validation loss: 0.00% done
Time: 0.17 s
Calculating validation loss: 20.00% done
Time: 139.12 s
Calculating validation loss: 40.00% done
Time: 282.19 s
Calculating validation loss: 60.00% done
Time: 443.09 s
Calculating validation loss: 80.00% done
Time: 602.51 s

Validation loss: 1.0724448610385555

Time taken: 755.50 s
Saving model to data/tamil/models/8/phones_split_after_embedding2024-07-10_22:09:02_checkpoint_epoch_1.pt

Dataset generation time limit reached: 240 s.
Number of classes remaining: 262.
Epoch 2: 0.01% done
Loss: 0.6599912047386169
Time: 0.92 s
Epoch 2: 10.01% done
Loss: 0.9235048346149112
Time: 246.46 s
Epoch 2: 20.01% done
Loss: 0.9024899673114702
Time: 487.51 s
Epoch 2: 30.00% done
Loss: 0.9003366825071354
Time: 732.34 s
Epoch 2: 40.00% done
Loss: 0.8778773497609259
Time: 983.67 s
Epoch 2: 50.01% done
Loss: 0.894861616866318
Time: 1241.96 s
Epoch 2: 60.01% done
Loss: 0.885920696871952
Time: 1493.86 s
Epoch 2: 70.01% done
Loss: 0.8822323328661688
Time: 1747.33 s
Epoch 2: 80.00% done
Loss: 0.8788537689204355
Time: 1999.31 s
Epoch 2: 90.00% done
Loss: 0.8874042281826723
Time: 2252.38 s

Epoch 2 done
Epoch loss: 0.8917124317273702

Time taken for epoch: 2501.82 s
Number of gradients clipped: 0

Calculating validation loss: 0.00% done
Time: 0.11 s
Calculating validation loss: 20.00% done
Time: 155.27 s
Calculating validation loss: 40.00% done
Time: 309.50 s
Calculating validation loss: 60.00% done
Time: 465.41 s
Calculating validation loss: 80.00% done
Time: 622.10 s

Validation loss: 0.9974363974701524

Time taken: 780.02 s
Saving model to data/tamil/models/8/phones_split_after_embedding2024-07-10_22:09:02_checkpoint_epoch_2.pt

Dataset generation time limit reached: 240 s.
Number of classes remaining: 269.
Epoch 3: 0.01% done
Loss: 0.7650594115257263
Time: 0.91 s
Epoch 3: 10.01% done
Loss: 0.8910286345765821
Time: 245.93 s
Epoch 3: 20.01% done
Loss: 0.8898371161866238
Time: 488.23 s
Epoch 3: 30.01% done
Loss: 0.9007620626651286
Time: 736.25 s
Epoch 3: 40.01% done
Loss: 0.8745209545937407
Time: 973.28 s
Epoch 3: 50.01% done
Loss: 0.8912541510143319
Time: 1216.28 s
Epoch 3: 60.00% done
Loss: 0.8884289252439809
Time: 1461.79 s
Epoch 3: 70.00% done
Loss: 0.8661866710048927
Time: 1698.95 s
Epoch 3: 80.00% done
Loss: 0.8565794771701648
Time: 1933.89 s
Epoch 3: 90.00% done
Loss: 0.8590525139651014
Time: 2170.83 s

Epoch 3 done
Epoch loss: 0.87804024221471

Time taken for epoch: 2412.32 s
Number of gradients clipped: 0

Calculating validation loss: 0.00% done
Time: 0.02 s
Calculating validation loss: 20.00% done
Time: 153.55 s
Calculating validation loss: 40.00% done
Time: 309.57 s
Calculating validation loss: 60.00% done
Time: 470.74 s
Calculating validation loss: 80.00% done
Time: 628.74 s

Validation loss: 0.9355184321967687

Time taken: 786.47 s
Saving model to data/tamil/models/8/phones_split_after_embedding2024-07-10_22:09:02_checkpoint_epoch_3.pt

Traceback (most recent call last):
  File "/work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/serialization.py", line 423, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/serialization.py", line 650, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
RuntimeError: [enforce fail at inline_container.cc:445] . PytorchStreamWriter failed writing file data/27: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/awe_model/train_model.py", line 246, in <module>
    save_model(model, optimizer, epoch_num, model_save_dir, model_file_basename, valid_loss)
  File "/mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/awe_model/train_model.py", line 167, in save_model
    torch.save(state_dict, save_fname)
  File "/work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/serialization.py", line 422, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/serialization.py", line 290, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:325] . unexpected pos 18918464 vs 18918356
terminate called after throwing an instance of 'c10::Error'
  what():  [enforce fail at inline_container.cc:325] . unexpected pos 18918464 vs 18918356
frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x55 (0x14b044ce12f5 in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x3cbaccc (0x14b0740faccc in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: mz_zip_writer_add_mem_ex_v2 + 0x5c5 (0x14b0740f4615 in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xb9 (0x14b0740fc2b9 in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0x2c3 (0x14b0740fc783 in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x125 (0x14b0740fc9f5 in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #6: <unknown function> + 0x806915 (0x14b09ad91915 in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x3c77f3 (0x14b09a9527f3 in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x3c86cf (0x14b09a9536cf in /work/y07/shared/cirrus-software/pytorch/1.13.1-gpu/python/3.10.8/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #9: /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python() [0x4f7798]
frame #10: /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python() [0x507744]
frame #11: /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python() [0x507770]
frame #12: /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python() [0x507770]
frame #13: /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python() [0x4e0952]
frame #14: PyDict_SetItemString + 0x52 (0x4e3b12 in /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python)
frame #15: /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python() [0x5c7c54]
frame #16: Py_FinalizeEx + 0x164 (0x5c6d44 in /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python)
frame #17: Py_RunMain + 0x109 (0x5b8bf9 in /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python)
frame #18: Py_BytesMain + 0x39 (0x587c29 in /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python)
frame #19: __libc_start_main + 0xf3 (0x14b0bd561493 in /lib64/libc.so.6)
frame #20: /mnt/lustre/e1000/home/tc062/tc062/sanjayb/dissertation/mhubert_model/hubert_env_gpu/bin/python() [0x587ade]

srun: error: r2i4n0: task 0: Aborted (core dumped)
srun: launch/slurm: _step_signal: Terminating StepId=5800265.0
